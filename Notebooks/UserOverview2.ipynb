{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/media/moraa/New Volume/Ontita/10Academy/Cohort B/Projects/Week1/User_Analytics_in_the_telecommunication_Industry')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from utils.db_connections import DBConnection\n",
    "from utils.clean import DataCleaner\n",
    "from utils.plots import plot_distribution, plot_boxplot, plot_heatmap, plot_countplot, plot_histplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of DBConnection\n",
    "db_conn = DBConnection()\n",
    "\n",
    "# Specify the table name you want to read\n",
    "table_name = 'xdr_data'\n",
    "\n",
    "# Read data from the specified table into a DataFrame\n",
    "df = db_conn.read_table_to_dataframe(table_name)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of DataCleaner\n",
    "cleaner = DataCleaner()\n",
    "\n",
    "# Remove columns with missing values exceeding the threshold\n",
    "df = cleaner.remove_columns_with_missing_values(df)\n",
    "\n",
    "# Fill missing values in numerical columns\n",
    "df = cleaner.fill_missing_values_numerical(df)\n",
    "\n",
    "# Fill missing values in categorical columns\n",
    "df = cleaner.fill_missing_values_categorical(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Print numerical columns\n",
    "print(\"Numerical Columns:\")\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object'])\n",
    "\n",
    "# Print categorical columns\n",
    "print(\"\\nCategorical Columns:\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for subplots\n",
    "num_cols = len(numerical_cols.columns)\n",
    "num_rows = (num_cols + 2) // 3  # Adjust as needed\n",
    "\n",
    "# Create boxplots for each numerical column\n",
    "plt.figure(figsize=(18, num_rows * 6))  # Adjust the figure height based on the number of rows\n",
    "for i, col in enumerate(numerical_cols.columns):\n",
    "    plt.subplot(num_rows, 3, i+1)  # Adjust the subplot layout\n",
    "    plt.boxplot(df[col], vert=False)\n",
    "    plt.title('Boxplot of ' + col)\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Overview Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute Dispersion Parameters\n",
    "dispersion_params = {}\n",
    "for col in numerical_cols.columns:\n",
    "    data = numerical_cols[col]\n",
    "    # Range\n",
    "    data_range = data.max() - data.min()\n",
    "    # Variance\n",
    "    data_variance = data.var()\n",
    "    # Standard Deviation\n",
    "    data_std_dev = data.std()\n",
    "    # Interquartile Range (IQR)\n",
    "    data_iqr = data.quantile(0.75) - data.quantile(0.25)\n",
    "    \n",
    "    dispersion_params[col] = {\n",
    "        'Range': data_range,\n",
    "        'Variance': data_variance,\n",
    "        'Standard Deviation': data_std_dev,\n",
    "        'Interquartile Range (IQR)': data_iqr\n",
    "    }\n",
    "\n",
    "# Step 3: Interpretation\n",
    "for col, params in dispersion_params.items():\n",
    "    print(f\"Dispersion Parameters for {col}:\")\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for subplots\n",
    "num_cols = len(numerical_cols.columns)\n",
    "num_rows = (num_cols // 3) + (num_cols % 3 > 0)  # Calculate number of rows needed\n",
    "\n",
    "# Create a single figure for all histograms\n",
    "plt.figure(figsize=(18, 12))  # Larger figsize\n",
    "\n",
    "# Loop through each numerical column and plot the histogram\n",
    "for i, col in enumerate(numerical_cols.columns, 1):  # Start subplot index from 1\n",
    "    plt.subplot(num_rows, 3, i)\n",
    "    plot_histplot(df, x_column=col, y_column=None)  # Assuming y_column is not needed\n",
    "    plt.title('Histogram of ' + col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for numerical columns\n",
    "plt.figure(figsize=(18, 12))  # Larger figsize\n",
    "num_cols = len(numerical_cols.columns)\n",
    "num_rows = (num_cols // 3) + (num_cols % 3 > 0)  # Calculate number of rows needed\n",
    "for i, col in enumerate(numerical_cols.columns):\n",
    "    plt.subplot(3, num_rows, i+1)\n",
    "    sns.boxplot(y=numerical_cols[col])\n",
    "    plt.title('Boxplot of ' + col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select pairs of quantitative columns for scatter plot visualization\n",
    "quantitative_pairs = [('Total UL (Bytes)', 'Total DL (Bytes)'),\n",
    "                      ('Social Media DL (Bytes)', 'Social Media UL (Bytes)')]\n",
    "\n",
    "# Plot scatter plots for quantitative pairs\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, pair in enumerate(quantitative_pairs):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    sns.scatterplot(x=pair[0], y=pair[1], data=df)\n",
    "    plt.title('Scatter Plot of ' + pair[0] + ' vs ' + pair[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure with a larger size\n",
    "plt.figure(figsize=(16, 10))  # Adjust the figsize as needed\n",
    "\n",
    "# Determine the number of rows and columns for subplots\n",
    "num_cols = 3  # Set the number of columns\n",
    "num_rows = (len(categorical_cols.columns) - 1) // num_cols + 1  # Calculate the number of rows dynamically\n",
    "\n",
    "# Loop through each categorical column and create a subplot\n",
    "for i, col in enumerate(categorical_cols.columns):\n",
    "    plt.subplot(num_rows, num_cols, i+1)  # Adjust the subplot layout as needed\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title('Bar Plot of ' + col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series for 'Start' variable\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=categorical_cols['Start'], y=categorical_cols.index, data=df)\n",
    "plt.title('Time Series Plot of Start Timestamp')\n",
    "plt.xlabel('Start Timestamp')\n",
    "plt.ylabel('Index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames along axis 1 (columns)\n",
    "combined_df = pd.concat([categorical_cols, numerical_cols], axis=1)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for applications data volume\n",
    "# Adjust application column names to include suffixes\n",
    "applications_columns = ['Social Media DL (Bytes)', 'Google DL (Bytes)', 'Email DL (Bytes)', \n",
    "                        'Youtube DL (Bytes)', 'Netflix DL (Bytes)', 'Gaming DL (Bytes)', 'Other DL (Bytes)',\n",
    "                        'Social Media UL (Bytes)', 'Google UL (Bytes)', 'Email UL (Bytes)', \n",
    "                        'Youtube UL (Bytes)', 'Netflix UL (Bytes)', 'Gaming UL (Bytes)', 'Other UL (Bytes)']\n",
    "\n",
    "\n",
    "# Calculate the correlation coefficients\n",
    "correlation = combined_df[applications_columns].corrwith(combined_df['Total DL (Bytes)'] + combined_df['Total UL (Bytes)'])\n",
    "\n",
    "print(\"Correlation coefficients between each application and Total DL+UL data:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert correlation to DataFrame for plotting\n",
    "correlation_df = pd.DataFrame(correlation, columns=['Correlation'])\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_df.transpose(), annot=True, cmap='coolwarm', cbar=False)\n",
    "plt.title('Correlation between Applications and Total DL+UL Data Volume')\n",
    "plt.xlabel('Applications')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total duration for all sessions for each user\n",
    "combined_df['Total Duration (s)'] = (combined_df['Dur. (ms)'] + combined_df['Dur. (ms).1']) / 1000\n",
    "\n",
    "# Group by MSISDN/Number (user) and calculate the total duration\n",
    "user_total_duration = combined_df.groupby('MSISDN/Number')['Total Duration (s)'].sum()\n",
    "\n",
    "# Segment users into deciles based on total duration\n",
    "user_total_duration_deciles = pd.qcut(user_total_duration, q=10, labels=False)\n",
    "\n",
    "# Assign decile class to each user in the original DataFrame\n",
    "combined_df['Decile Class'] = combined_df['MSISDN/Number'].map(user_total_duration_deciles)\n",
    "\n",
    "# Compute the total data (DL+UL) for each decile class\n",
    "total_data_per_decile = combined_df.groupby('Decile Class')[['Total DL (Bytes)', 'Total UL (Bytes)']].sum()\n",
    "\n",
    "# Compute the total data (DL+UL) in bytes\n",
    "total_data_per_decile['Total Data (DL+UL)'] = total_data_per_decile['Total DL (Bytes)'] + total_data_per_decile['Total UL (Bytes)']\n",
    "\n",
    "# Sort the deciles by total data in descending order\n",
    "total_data_per_decile.sort_values(by='Total Data (DL+UL)', ascending=False, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Total data (DL+UL) per decile class:\")\n",
    "print(total_data_per_decile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns for correlation analysis\n",
    "selected_columns = ['Social Media DL (Bytes)', 'Google DL (Bytes)', 'Email DL (Bytes)',\n",
    "                    'Youtube DL (Bytes)', 'Netflix DL (Bytes)', 'Gaming DL (Bytes)',\n",
    "                    'Other DL (Bytes)']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = combined_df[selected_columns].corr()\n",
    "\n",
    "# Interpret the findings\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)  # You can adjust the number of components as needed\n",
    "principal_components = pca.fit_transform(combined_df)\n",
    "\n",
    "# Create a DataFrame to store the principal components\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the principal components \n",
    "plt.scatter(principal_df['PC1'], principal_df['PC2'])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns for PCA\n",
    "selected_columns = ['Social Media DL (Bytes)', 'Google DL (Bytes)', 'Email DL (Bytes)',\n",
    "                    'Youtube DL (Bytes)', 'Netflix DL (Bytes)', 'Gaming DL (Bytes)',\n",
    "                    'Other DL (Bytes)']\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)  # You can adjust the number of components as needed\n",
    "principal_components = pca.fit_transform(combined_df[selected_columns])\n",
    "\n",
    "# Create a DataFrame to store the principal components\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
